{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ffe4dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import chess\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c60842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LMDBDataset import LMDBDataset\n",
    "\n",
    "dataset = LMDBDataset(\"../../data/lmdb/\")\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdca927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x, y = dataset[5]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5bbbace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4505)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "347499fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość batchy: 12188\n",
      "ilość pozycji:  1560064\n"
     ]
    }
   ],
   "source": [
    "print(\"Ilość batchy:\", len(loader))\n",
    "print(\"ilość pozycji: \", len(loader)*loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e9565b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23086bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/12188], Loss: 6.5733\n",
      "Epoch [1/6], Step [200/12188], Loss: 6.0363\n",
      "Epoch [1/6], Step [300/12188], Loss: 5.9003\n",
      "Epoch [1/6], Step [400/12188], Loss: 5.7840\n",
      "Epoch [1/6], Step [500/12188], Loss: 5.6578\n",
      "Epoch [1/6], Step [600/12188], Loss: 5.4864\n",
      "Epoch [1/6], Step [700/12188], Loss: 5.2605\n",
      "Epoch [1/6], Step [800/12188], Loss: 4.9730\n",
      "Epoch [1/6], Step [900/12188], Loss: 4.7060\n",
      "Epoch [1/6], Step [1000/12188], Loss: 4.4969\n",
      "Epoch [1/6], Step [1100/12188], Loss: 4.2716\n",
      "Epoch [1/6], Step [1200/12188], Loss: 4.0838\n",
      "Epoch [1/6], Step [1300/12188], Loss: 3.9752\n",
      "Epoch [1/6], Step [1400/12188], Loss: 3.8805\n",
      "Epoch [1/6], Step [1500/12188], Loss: 3.7889\n",
      "Epoch [1/6], Step [1600/12188], Loss: 3.7557\n",
      "Epoch [1/6], Step [1700/12188], Loss: 3.6689\n",
      "Epoch [1/6], Step [1800/12188], Loss: 3.6423\n",
      "Epoch [1/6], Step [1900/12188], Loss: 3.5547\n",
      "Epoch [1/6], Step [2000/12188], Loss: 3.5108\n",
      "Epoch [1/6], Step [2100/12188], Loss: 3.5013\n",
      "Epoch [1/6], Step [2200/12188], Loss: 3.4561\n",
      "Epoch [1/6], Step [2300/12188], Loss: 3.4347\n",
      "Epoch [1/6], Step [2400/12188], Loss: 3.3716\n",
      "Epoch [1/6], Step [2500/12188], Loss: 3.3689\n",
      "Epoch [1/6], Step [2600/12188], Loss: 3.3096\n",
      "Epoch [1/6], Step [2700/12188], Loss: 3.3070\n",
      "Epoch [1/6], Step [2800/12188], Loss: 3.2657\n",
      "Epoch [1/6], Step [2900/12188], Loss: 3.2510\n",
      "Epoch [1/6], Step [3000/12188], Loss: 3.1915\n",
      "Epoch [1/6], Step [3100/12188], Loss: 3.2130\n",
      "Epoch [1/6], Step [3200/12188], Loss: 3.1814\n",
      "Epoch [1/6], Step [3300/12188], Loss: 3.1750\n",
      "Epoch [1/6], Step [3400/12188], Loss: 3.1400\n",
      "Epoch [1/6], Step [3500/12188], Loss: 3.1262\n",
      "Epoch [1/6], Step [3600/12188], Loss: 3.1048\n",
      "Epoch [1/6], Step [3700/12188], Loss: 3.0892\n",
      "Epoch [1/6], Step [3800/12188], Loss: 3.0400\n",
      "Epoch [1/6], Step [3900/12188], Loss: 3.0831\n",
      "Epoch [1/6], Step [4000/12188], Loss: 3.0316\n",
      "Epoch [1/6], Step [4100/12188], Loss: 3.0201\n",
      "Epoch [1/6], Step [4200/12188], Loss: 2.9959\n",
      "Epoch [1/6], Step [4300/12188], Loss: 2.9915\n",
      "Epoch [1/6], Step [4400/12188], Loss: 2.9659\n",
      "Epoch [1/6], Step [4500/12188], Loss: 2.9798\n",
      "Epoch [1/6], Step [4600/12188], Loss: 2.9693\n",
      "Epoch [1/6], Step [4700/12188], Loss: 2.9163\n",
      "Epoch [1/6], Step [4800/12188], Loss: 2.9366\n",
      "Epoch [1/6], Step [4900/12188], Loss: 2.9305\n",
      "Epoch [1/6], Step [5000/12188], Loss: 2.9191\n",
      "Epoch [1/6], Step [5100/12188], Loss: 2.8808\n",
      "Epoch [1/6], Step [5200/12188], Loss: 2.9073\n",
      "Epoch [1/6], Step [5300/12188], Loss: 2.9036\n",
      "Epoch [1/6], Step [5400/12188], Loss: 2.9009\n",
      "Epoch [1/6], Step [5500/12188], Loss: 2.8483\n",
      "Epoch [1/6], Step [5600/12188], Loss: 2.8323\n",
      "Epoch [1/6], Step [5700/12188], Loss: 2.8414\n",
      "Epoch [1/6], Step [5800/12188], Loss: 2.8378\n",
      "Epoch [1/6], Step [5900/12188], Loss: 2.8432\n",
      "Epoch [1/6], Step [6000/12188], Loss: 2.8589\n",
      "Epoch [1/6], Step [6100/12188], Loss: 2.8020\n",
      "Epoch [1/6], Step [6200/12188], Loss: 2.7907\n",
      "Epoch [1/6], Step [6300/12188], Loss: 2.8048\n",
      "Epoch [1/6], Step [6400/12188], Loss: 2.7832\n",
      "Epoch [1/6], Step [6500/12188], Loss: 2.7973\n",
      "Epoch [1/6], Step [6600/12188], Loss: 2.7960\n",
      "Epoch [1/6], Step [6700/12188], Loss: 2.7388\n",
      "Epoch [1/6], Step [6800/12188], Loss: 2.7431\n",
      "Epoch [1/6], Step [6900/12188], Loss: 2.7454\n",
      "Epoch [1/6], Step [7000/12188], Loss: 2.7236\n",
      "Epoch [1/6], Step [7100/12188], Loss: 2.7650\n",
      "Epoch [1/6], Step [7200/12188], Loss: 2.7406\n",
      "Epoch [1/6], Step [7300/12188], Loss: 2.7347\n",
      "Epoch [1/6], Step [7400/12188], Loss: 2.7015\n",
      "Epoch [1/6], Step [7500/12188], Loss: 2.7031\n",
      "Epoch [1/6], Step [7600/12188], Loss: 2.6736\n",
      "Epoch [1/6], Step [7700/12188], Loss: 2.7088\n",
      "Epoch [1/6], Step [7800/12188], Loss: 2.7178\n",
      "Epoch [1/6], Step [7900/12188], Loss: 2.6918\n",
      "Epoch [1/6], Step [8000/12188], Loss: 2.6626\n",
      "Epoch [1/6], Step [8100/12188], Loss: 2.6829\n",
      "Epoch [1/6], Step [8200/12188], Loss: 2.6694\n",
      "Epoch [1/6], Step [8300/12188], Loss: 2.6490\n",
      "Epoch [1/6], Step [8400/12188], Loss: 2.6662\n",
      "Epoch [1/6], Step [8500/12188], Loss: 2.6475\n",
      "Epoch [1/6], Step [8600/12188], Loss: 2.6329\n",
      "Epoch [1/6], Step [8700/12188], Loss: 2.6649\n",
      "Epoch [1/6], Step [8800/12188], Loss: 2.6364\n",
      "Epoch [1/6], Step [8900/12188], Loss: 2.6251\n",
      "Epoch [1/6], Step [9000/12188], Loss: 2.6214\n",
      "Epoch [1/6], Step [9100/12188], Loss: 2.6114\n",
      "Epoch [1/6], Step [9200/12188], Loss: 2.6003\n",
      "Epoch [1/6], Step [9300/12188], Loss: 2.5979\n",
      "Epoch [1/6], Step [9400/12188], Loss: 2.6018\n",
      "Epoch [1/6], Step [9500/12188], Loss: 2.5940\n",
      "Epoch [1/6], Step [9600/12188], Loss: 2.6089\n",
      "Epoch [1/6], Step [9700/12188], Loss: 2.5740\n",
      "Epoch [1/6], Step [9800/12188], Loss: 2.5698\n",
      "Epoch [1/6], Step [9900/12188], Loss: 2.5891\n",
      "Epoch [1/6], Step [10000/12188], Loss: 2.5774\n",
      "Epoch [1/6], Step [10100/12188], Loss: 2.6061\n",
      "Epoch [1/6], Step [10200/12188], Loss: 2.5707\n",
      "Epoch [1/6], Step [10300/12188], Loss: 2.5747\n",
      "Epoch [1/6], Step [10400/12188], Loss: 2.5485\n",
      "Epoch [1/6], Step [10500/12188], Loss: 2.5473\n",
      "Epoch [1/6], Step [10600/12188], Loss: 2.5626\n",
      "Epoch [1/6], Step [10700/12188], Loss: 2.5160\n",
      "Epoch [1/6], Step [10800/12188], Loss: 2.5420\n",
      "Epoch [1/6], Step [10900/12188], Loss: 2.5493\n",
      "Epoch [1/6], Step [11000/12188], Loss: 2.5276\n",
      "Epoch [1/6], Step [11100/12188], Loss: 2.5330\n",
      "Epoch [1/6], Step [11200/12188], Loss: 2.5048\n",
      "Epoch [1/6], Step [11300/12188], Loss: 2.5294\n",
      "Epoch [1/6], Step [11400/12188], Loss: 2.5206\n",
      "Epoch [1/6], Step [11500/12188], Loss: 2.5302\n",
      "Epoch [1/6], Step [11600/12188], Loss: 2.5027\n",
      "Epoch [1/6], Step [11700/12188], Loss: 2.4858\n",
      "Epoch [1/6], Step [11800/12188], Loss: 2.5059\n",
      "Epoch [1/6], Step [11900/12188], Loss: 2.4955\n",
      "Epoch [1/6], Step [12000/12188], Loss: 2.4871\n",
      "Epoch [1/6], Step [12100/12188], Loss: 2.4748\n",
      "Epoch [2/6], Step [100/12188], Loss: 2.2370\n",
      "Epoch [2/6], Step [200/12188], Loss: 2.2011\n",
      "Epoch [2/6], Step [300/12188], Loss: 2.1991\n",
      "Epoch [2/6], Step [400/12188], Loss: 2.2238\n",
      "Epoch [2/6], Step [500/12188], Loss: 2.2005\n",
      "Epoch [2/6], Step [600/12188], Loss: 2.2064\n",
      "Epoch [2/6], Step [700/12188], Loss: 2.1951\n",
      "Epoch [2/6], Step [800/12188], Loss: 2.1893\n",
      "Epoch [2/6], Step [900/12188], Loss: 2.1961\n",
      "Epoch [2/6], Step [1000/12188], Loss: 2.2331\n",
      "Epoch [2/6], Step [1100/12188], Loss: 2.2127\n",
      "Epoch [2/6], Step [1200/12188], Loss: 2.2084\n",
      "Epoch [2/6], Step [1300/12188], Loss: 2.1964\n",
      "Epoch [2/6], Step [1400/12188], Loss: 2.2143\n",
      "Epoch [2/6], Step [1500/12188], Loss: 2.2056\n",
      "Epoch [2/6], Step [1600/12188], Loss: 2.2265\n",
      "Epoch [2/6], Step [1700/12188], Loss: 2.2011\n",
      "Epoch [2/6], Step [1800/12188], Loss: 2.1986\n",
      "Epoch [2/6], Step [1900/12188], Loss: 2.2102\n",
      "Epoch [2/6], Step [2000/12188], Loss: 2.2214\n",
      "Epoch [2/6], Step [2100/12188], Loss: 2.2089\n",
      "Epoch [2/6], Step [2200/12188], Loss: 2.2226\n",
      "Epoch [2/6], Step [2300/12188], Loss: 2.2100\n",
      "Epoch [2/6], Step [2400/12188], Loss: 2.1994\n",
      "Epoch [2/6], Step [2500/12188], Loss: 2.2074\n",
      "Epoch [2/6], Step [2600/12188], Loss: 2.1983\n",
      "Epoch [2/6], Step [2700/12188], Loss: 2.2115\n",
      "Epoch [2/6], Step [2800/12188], Loss: 2.2229\n",
      "Epoch [2/6], Step [2900/12188], Loss: 2.2104\n",
      "Epoch [2/6], Step [3000/12188], Loss: 2.1914\n",
      "Epoch [2/6], Step [3100/12188], Loss: 2.2303\n",
      "Epoch [2/6], Step [3200/12188], Loss: 2.2171\n",
      "Epoch [2/6], Step [3300/12188], Loss: 2.1982\n",
      "Epoch [2/6], Step [3400/12188], Loss: 2.2218\n",
      "Epoch [2/6], Step [3500/12188], Loss: 2.2162\n",
      "Epoch [2/6], Step [3600/12188], Loss: 2.1882\n",
      "Epoch [2/6], Step [3700/12188], Loss: 2.2236\n",
      "Epoch [2/6], Step [3800/12188], Loss: 2.2072\n",
      "Epoch [2/6], Step [3900/12188], Loss: 2.1894\n",
      "Epoch [2/6], Step [4000/12188], Loss: 2.2057\n",
      "Epoch [2/6], Step [4100/12188], Loss: 2.2148\n",
      "Epoch [2/6], Step [4200/12188], Loss: 2.2105\n",
      "Epoch [2/6], Step [4300/12188], Loss: 2.2045\n",
      "Epoch [2/6], Step [4400/12188], Loss: 2.1986\n",
      "Epoch [2/6], Step [4500/12188], Loss: 2.2034\n",
      "Epoch [2/6], Step [4600/12188], Loss: 2.1988\n",
      "Epoch [2/6], Step [4700/12188], Loss: 2.1831\n",
      "Epoch [2/6], Step [4800/12188], Loss: 2.2038\n",
      "Epoch [2/6], Step [4900/12188], Loss: 2.2040\n",
      "Epoch [2/6], Step [5000/12188], Loss: 2.1998\n",
      "Epoch [2/6], Step [5100/12188], Loss: 2.2157\n",
      "Epoch [2/6], Step [5200/12188], Loss: 2.1831\n",
      "Epoch [2/6], Step [5300/12188], Loss: 2.2106\n",
      "Epoch [2/6], Step [5400/12188], Loss: 2.2066\n",
      "Epoch [2/6], Step [5500/12188], Loss: 2.2013\n",
      "Epoch [2/6], Step [5600/12188], Loss: 2.1880\n",
      "Epoch [2/6], Step [5700/12188], Loss: 2.2061\n",
      "Epoch [2/6], Step [5800/12188], Loss: 2.1927\n",
      "Epoch [2/6], Step [5900/12188], Loss: 2.2022\n",
      "Epoch [2/6], Step [6000/12188], Loss: 2.2135\n",
      "Epoch [2/6], Step [6100/12188], Loss: 2.2173\n",
      "Epoch [2/6], Step [6200/12188], Loss: 2.2113\n",
      "Epoch [2/6], Step [6300/12188], Loss: 2.2042\n",
      "Epoch [2/6], Step [6400/12188], Loss: 2.1837\n",
      "Epoch [2/6], Step [6500/12188], Loss: 2.1895\n",
      "Epoch [2/6], Step [6600/12188], Loss: 2.2016\n",
      "Epoch [2/6], Step [6700/12188], Loss: 2.1919\n",
      "Epoch [2/6], Step [6800/12188], Loss: 2.1882\n",
      "Epoch [2/6], Step [6900/12188], Loss: 2.1803\n",
      "Epoch [2/6], Step [7000/12188], Loss: 2.1991\n",
      "Epoch [2/6], Step [7100/12188], Loss: 2.1986\n",
      "Epoch [2/6], Step [7200/12188], Loss: 2.1773\n",
      "Epoch [2/6], Step [7300/12188], Loss: 2.1897\n",
      "Epoch [2/6], Step [7400/12188], Loss: 2.1626\n",
      "Epoch [2/6], Step [7500/12188], Loss: 2.2049\n",
      "Epoch [2/6], Step [7600/12188], Loss: 2.1876\n",
      "Epoch [2/6], Step [7700/12188], Loss: 2.2032\n",
      "Epoch [2/6], Step [7800/12188], Loss: 2.1714\n",
      "Epoch [2/6], Step [7900/12188], Loss: 2.1862\n",
      "Epoch [2/6], Step [8000/12188], Loss: 2.1852\n",
      "Epoch [2/6], Step [8100/12188], Loss: 2.1890\n",
      "Epoch [2/6], Step [8200/12188], Loss: 2.1699\n",
      "Epoch [2/6], Step [8300/12188], Loss: 2.1980\n",
      "Epoch [2/6], Step [8400/12188], Loss: 2.1937\n",
      "Epoch [2/6], Step [8500/12188], Loss: 2.1745\n",
      "Epoch [2/6], Step [8600/12188], Loss: 2.1925\n",
      "Epoch [2/6], Step [8700/12188], Loss: 2.1931\n",
      "Epoch [2/6], Step [8800/12188], Loss: 2.1617\n",
      "Epoch [2/6], Step [8900/12188], Loss: 2.1764\n",
      "Epoch [2/6], Step [9000/12188], Loss: 2.1902\n",
      "Epoch [2/6], Step [9100/12188], Loss: 2.1840\n",
      "Epoch [2/6], Step [9200/12188], Loss: 2.1829\n",
      "Epoch [2/6], Step [9300/12188], Loss: 2.1697\n",
      "Epoch [2/6], Step [9400/12188], Loss: 2.1685\n",
      "Epoch [2/6], Step [9500/12188], Loss: 2.1715\n",
      "Epoch [2/6], Step [9600/12188], Loss: 2.1693\n",
      "Epoch [2/6], Step [9700/12188], Loss: 2.1684\n",
      "Epoch [2/6], Step [9800/12188], Loss: 2.1574\n",
      "Epoch [2/6], Step [9900/12188], Loss: 2.1730\n",
      "Epoch [2/6], Step [10000/12188], Loss: 2.1768\n",
      "Epoch [2/6], Step [10100/12188], Loss: 2.1676\n",
      "Epoch [2/6], Step [10200/12188], Loss: 2.1818\n",
      "Epoch [2/6], Step [10300/12188], Loss: 2.1714\n",
      "Epoch [2/6], Step [10400/12188], Loss: 2.1780\n",
      "Epoch [2/6], Step [10500/12188], Loss: 2.1656\n",
      "Epoch [2/6], Step [10600/12188], Loss: 2.1779\n",
      "Epoch [2/6], Step [10700/12188], Loss: 2.1765\n",
      "Epoch [2/6], Step [10800/12188], Loss: 2.1916\n",
      "Epoch [2/6], Step [10900/12188], Loss: 2.1689\n",
      "Epoch [2/6], Step [11000/12188], Loss: 2.1785\n",
      "Epoch [2/6], Step [11100/12188], Loss: 2.1568\n",
      "Epoch [2/6], Step [11200/12188], Loss: 2.1771\n",
      "Epoch [2/6], Step [11300/12188], Loss: 2.1796\n",
      "Epoch [2/6], Step [11400/12188], Loss: 2.1684\n",
      "Epoch [2/6], Step [11500/12188], Loss: 2.1658\n",
      "Epoch [2/6], Step [11600/12188], Loss: 2.1606\n",
      "Epoch [2/6], Step [11700/12188], Loss: 2.1560\n",
      "Epoch [2/6], Step [11800/12188], Loss: 2.1839\n",
      "Epoch [2/6], Step [11900/12188], Loss: 2.1517\n",
      "Epoch [2/6], Step [12000/12188], Loss: 2.1588\n",
      "Epoch [2/6], Step [12100/12188], Loss: 2.1444\n",
      "Epoch [3/6], Step [100/12188], Loss: 1.8385\n",
      "Epoch [3/6], Step [200/12188], Loss: 1.8402\n",
      "Epoch [3/6], Step [300/12188], Loss: 1.8430\n",
      "Epoch [3/6], Step [400/12188], Loss: 1.8510\n",
      "Epoch [3/6], Step [500/12188], Loss: 1.8406\n",
      "Epoch [3/6], Step [600/12188], Loss: 1.8137\n",
      "Epoch [3/6], Step [700/12188], Loss: 1.8830\n",
      "Epoch [3/6], Step [800/12188], Loss: 1.8660\n",
      "Epoch [3/6], Step [900/12188], Loss: 1.8487\n",
      "Epoch [3/6], Step [1000/12188], Loss: 1.8475\n",
      "Epoch [3/6], Step [1100/12188], Loss: 1.8582\n",
      "Epoch [3/6], Step [1200/12188], Loss: 1.8507\n",
      "Epoch [3/6], Step [1300/12188], Loss: 1.8562\n",
      "Epoch [3/6], Step [1400/12188], Loss: 1.8739\n",
      "Epoch [3/6], Step [1500/12188], Loss: 1.8743\n",
      "Epoch [3/6], Step [1600/12188], Loss: 1.8715\n",
      "Epoch [3/6], Step [1700/12188], Loss: 1.8810\n",
      "Epoch [3/6], Step [1800/12188], Loss: 1.8716\n",
      "Epoch [3/6], Step [1900/12188], Loss: 1.8828\n",
      "Epoch [3/6], Step [2000/12188], Loss: 1.8520\n",
      "Epoch [3/6], Step [2100/12188], Loss: 1.8661\n",
      "Epoch [3/6], Step [2200/12188], Loss: 1.8816\n",
      "Epoch [3/6], Step [2300/12188], Loss: 1.8945\n",
      "Epoch [3/6], Step [2400/12188], Loss: 1.8771\n",
      "Epoch [3/6], Step [2500/12188], Loss: 1.8829\n",
      "Epoch [3/6], Step [2600/12188], Loss: 1.8647\n",
      "Epoch [3/6], Step [2700/12188], Loss: 1.8773\n",
      "Epoch [3/6], Step [2800/12188], Loss: 1.8778\n",
      "Epoch [3/6], Step [2900/12188], Loss: 1.8822\n",
      "Epoch [3/6], Step [3000/12188], Loss: 1.8890\n",
      "Epoch [3/6], Step [3100/12188], Loss: 1.8815\n",
      "Epoch [3/6], Step [3200/12188], Loss: 1.8864\n",
      "Epoch [3/6], Step [3300/12188], Loss: 1.8762\n",
      "Epoch [3/6], Step [3400/12188], Loss: 1.8725\n",
      "Epoch [3/6], Step [3500/12188], Loss: 1.8784\n",
      "Epoch [3/6], Step [3600/12188], Loss: 1.8835\n",
      "Epoch [3/6], Step [3700/12188], Loss: 1.9308\n",
      "Epoch [3/6], Step [3800/12188], Loss: 1.8761\n",
      "Epoch [3/6], Step [3900/12188], Loss: 1.9290\n",
      "Epoch [3/6], Step [4000/12188], Loss: 1.9109\n",
      "Epoch [3/6], Step [4100/12188], Loss: 1.8769\n",
      "Epoch [3/6], Step [4200/12188], Loss: 1.9286\n",
      "Epoch [3/6], Step [4300/12188], Loss: 1.8976\n",
      "Epoch [3/6], Step [4400/12188], Loss: 1.8851\n",
      "Epoch [3/6], Step [4500/12188], Loss: 1.9014\n",
      "Epoch [3/6], Step [4600/12188], Loss: 1.8993\n",
      "Epoch [3/6], Step [4700/12188], Loss: 1.9055\n",
      "Epoch [3/6], Step [4800/12188], Loss: 1.9126\n",
      "Epoch [3/6], Step [4900/12188], Loss: 1.8965\n",
      "Epoch [3/6], Step [5000/12188], Loss: 1.9304\n",
      "Epoch [3/6], Step [5100/12188], Loss: 1.9027\n",
      "Epoch [3/6], Step [5200/12188], Loss: 1.9289\n",
      "Epoch [3/6], Step [5300/12188], Loss: 1.9076\n",
      "Epoch [3/6], Step [5400/12188], Loss: 1.9009\n",
      "Epoch [3/6], Step [5500/12188], Loss: 1.8815\n",
      "Epoch [3/6], Step [5600/12188], Loss: 1.9255\n",
      "Epoch [3/6], Step [5700/12188], Loss: 1.8950\n",
      "Epoch [3/6], Step [5800/12188], Loss: 1.9022\n",
      "Epoch [3/6], Step [5900/12188], Loss: 1.9239\n",
      "Epoch [3/6], Step [6000/12188], Loss: 1.9075\n",
      "Epoch [3/6], Step [6100/12188], Loss: 1.9269\n",
      "Epoch [3/6], Step [6200/12188], Loss: 1.9161\n",
      "Epoch [3/6], Step [6300/12188], Loss: 1.9312\n",
      "Epoch [3/6], Step [6400/12188], Loss: 1.9195\n",
      "Epoch [3/6], Step [6500/12188], Loss: 1.9155\n",
      "Epoch [3/6], Step [6600/12188], Loss: 1.9072\n",
      "Epoch [3/6], Step [6700/12188], Loss: 1.9203\n",
      "Epoch [3/6], Step [6800/12188], Loss: 1.9075\n",
      "Epoch [3/6], Step [6900/12188], Loss: 1.9141\n",
      "Epoch [3/6], Step [7000/12188], Loss: 1.9139\n",
      "Epoch [3/6], Step [7100/12188], Loss: 1.9202\n",
      "Epoch [3/6], Step [7200/12188], Loss: 1.9300\n",
      "Epoch [3/6], Step [7300/12188], Loss: 1.9229\n",
      "Epoch [3/6], Step [7400/12188], Loss: 1.9304\n",
      "Epoch [3/6], Step [7500/12188], Loss: 1.9240\n",
      "Epoch [3/6], Step [7600/12188], Loss: 1.9083\n",
      "Epoch [3/6], Step [7700/12188], Loss: 1.9317\n",
      "Epoch [3/6], Step [7800/12188], Loss: 1.9377\n",
      "Epoch [3/6], Step [7900/12188], Loss: 1.9322\n",
      "Epoch [3/6], Step [8000/12188], Loss: 1.9436\n",
      "Epoch [3/6], Step [8100/12188], Loss: 1.9338\n",
      "Epoch [3/6], Step [8200/12188], Loss: 1.9406\n",
      "Epoch [3/6], Step [8300/12188], Loss: 1.9313\n",
      "Epoch [3/6], Step [8400/12188], Loss: 1.9178\n",
      "Epoch [3/6], Step [8500/12188], Loss: 1.9281\n",
      "Epoch [3/6], Step [8600/12188], Loss: 1.9547\n",
      "Epoch [3/6], Step [8700/12188], Loss: 1.9045\n",
      "Epoch [3/6], Step [8800/12188], Loss: 1.9382\n",
      "Epoch [3/6], Step [8900/12188], Loss: 1.9272\n",
      "Epoch [3/6], Step [9000/12188], Loss: 1.9398\n",
      "Epoch [3/6], Step [9100/12188], Loss: 1.9301\n",
      "Epoch [3/6], Step [9200/12188], Loss: 1.9515\n",
      "Epoch [3/6], Step [9300/12188], Loss: 1.9454\n",
      "Epoch [3/6], Step [9400/12188], Loss: 1.9304\n",
      "Epoch [3/6], Step [9500/12188], Loss: 1.9367\n",
      "Epoch [3/6], Step [9600/12188], Loss: 1.9367\n",
      "Epoch [3/6], Step [9700/12188], Loss: 1.9379\n",
      "Epoch [3/6], Step [9800/12188], Loss: 1.9499\n",
      "Epoch [3/6], Step [9900/12188], Loss: 1.9176\n",
      "Epoch [3/6], Step [10000/12188], Loss: 1.9583\n",
      "Epoch [3/6], Step [10100/12188], Loss: 1.9511\n",
      "Epoch [3/6], Step [10200/12188], Loss: 1.9309\n",
      "Epoch [3/6], Step [10300/12188], Loss: 1.9263\n",
      "Epoch [3/6], Step [10400/12188], Loss: 1.9436\n",
      "Epoch [3/6], Step [10500/12188], Loss: 1.9295\n",
      "Epoch [3/6], Step [10600/12188], Loss: 1.9222\n",
      "Epoch [3/6], Step [10700/12188], Loss: 1.9392\n",
      "Epoch [3/6], Step [10800/12188], Loss: 1.9403\n",
      "Epoch [3/6], Step [10900/12188], Loss: 1.9123\n",
      "Epoch [3/6], Step [11000/12188], Loss: 1.9254\n",
      "Epoch [3/6], Step [11100/12188], Loss: 1.9495\n",
      "Epoch [3/6], Step [11200/12188], Loss: 1.9471\n",
      "Epoch [3/6], Step [11300/12188], Loss: 1.9636\n",
      "Epoch [3/6], Step [11400/12188], Loss: 1.9576\n",
      "Epoch [3/6], Step [11500/12188], Loss: 1.9671\n",
      "Epoch [3/6], Step [11600/12188], Loss: 1.9496\n",
      "Epoch [3/6], Step [11700/12188], Loss: 1.9252\n",
      "Epoch [3/6], Step [11800/12188], Loss: 1.9386\n",
      "Epoch [3/6], Step [11900/12188], Loss: 1.9449\n",
      "Epoch [3/6], Step [12000/12188], Loss: 1.9300\n",
      "Epoch [3/6], Step [12100/12188], Loss: 1.9535\n",
      "Epoch [4/6], Step [100/12188], Loss: 1.6053\n",
      "Epoch [4/6], Step [200/12188], Loss: 1.6186\n",
      "Epoch [4/6], Step [300/12188], Loss: 1.5937\n",
      "Epoch [4/6], Step [400/12188], Loss: 1.6065\n",
      "Epoch [4/6], Step [500/12188], Loss: 1.5923\n",
      "Epoch [4/6], Step [600/12188], Loss: 1.6023\n",
      "Epoch [4/6], Step [700/12188], Loss: 1.6265\n",
      "Epoch [4/6], Step [800/12188], Loss: 1.6365\n",
      "Epoch [4/6], Step [900/12188], Loss: 1.6288\n",
      "Epoch [4/6], Step [1000/12188], Loss: 1.6315\n",
      "Epoch [4/6], Step [1100/12188], Loss: 1.6350\n",
      "Epoch [4/6], Step [1200/12188], Loss: 1.6523\n",
      "Epoch [4/6], Step [1300/12188], Loss: 1.6322\n",
      "Epoch [4/6], Step [1400/12188], Loss: 1.6676\n",
      "Epoch [4/6], Step [1500/12188], Loss: 1.6178\n",
      "Epoch [4/6], Step [1600/12188], Loss: 1.6161\n",
      "Epoch [4/6], Step [1700/12188], Loss: 1.6412\n",
      "Epoch [4/6], Step [1800/12188], Loss: 1.6474\n",
      "Epoch [4/6], Step [1900/12188], Loss: 1.6415\n",
      "Epoch [4/6], Step [2000/12188], Loss: 1.6223\n",
      "Epoch [4/6], Step [2100/12188], Loss: 1.6634\n",
      "Epoch [4/6], Step [2200/12188], Loss: 1.6643\n",
      "Epoch [4/6], Step [2300/12188], Loss: 1.6703\n",
      "Epoch [4/6], Step [2400/12188], Loss: 1.6682\n",
      "Epoch [4/6], Step [2500/12188], Loss: 1.6473\n",
      "Epoch [4/6], Step [2600/12188], Loss: 1.6531\n",
      "Epoch [4/6], Step [2700/12188], Loss: 1.6580\n",
      "Epoch [4/6], Step [2800/12188], Loss: 1.6478\n",
      "Epoch [4/6], Step [2900/12188], Loss: 1.6598\n",
      "Epoch [4/6], Step [3000/12188], Loss: 1.6661\n",
      "Epoch [4/6], Step [3100/12188], Loss: 1.6672\n",
      "Epoch [4/6], Step [3200/12188], Loss: 1.6694\n",
      "Epoch [4/6], Step [3300/12188], Loss: 1.6718\n",
      "Epoch [4/6], Step [3400/12188], Loss: 1.6796\n",
      "Epoch [4/6], Step [3500/12188], Loss: 1.6835\n",
      "Epoch [4/6], Step [3600/12188], Loss: 1.6787\n",
      "Epoch [4/6], Step [3700/12188], Loss: 1.6799\n",
      "Epoch [4/6], Step [3800/12188], Loss: 1.6863\n",
      "Epoch [4/6], Step [3900/12188], Loss: 1.6557\n",
      "Epoch [4/6], Step [4000/12188], Loss: 1.6859\n",
      "Epoch [4/6], Step [4100/12188], Loss: 1.6569\n",
      "Epoch [4/6], Step [4200/12188], Loss: 1.6956\n",
      "Epoch [4/6], Step [4300/12188], Loss: 1.7022\n",
      "Epoch [4/6], Step [4400/12188], Loss: 1.6778\n",
      "Epoch [4/6], Step [4500/12188], Loss: 1.6921\n",
      "Epoch [4/6], Step [4600/12188], Loss: 1.6925\n",
      "Epoch [4/6], Step [4700/12188], Loss: 1.6913\n",
      "Epoch [4/6], Step [4800/12188], Loss: 1.6705\n",
      "Epoch [4/6], Step [4900/12188], Loss: 1.6870\n",
      "Epoch [4/6], Step [5000/12188], Loss: 1.7171\n",
      "Epoch [4/6], Step [5100/12188], Loss: 1.6855\n",
      "Epoch [4/6], Step [5200/12188], Loss: 1.6973\n",
      "Epoch [4/6], Step [5300/12188], Loss: 1.6847\n",
      "Epoch [4/6], Step [5400/12188], Loss: 1.7000\n",
      "Epoch [4/6], Step [5500/12188], Loss: 1.7173\n",
      "Epoch [4/6], Step [5600/12188], Loss: 1.7106\n",
      "Epoch [4/6], Step [5700/12188], Loss: 1.7146\n",
      "Epoch [4/6], Step [5800/12188], Loss: 1.6878\n",
      "Epoch [4/6], Step [5900/12188], Loss: 1.7353\n",
      "Epoch [4/6], Step [6000/12188], Loss: 1.7232\n",
      "Epoch [4/6], Step [6100/12188], Loss: 1.7248\n",
      "Epoch [4/6], Step [6200/12188], Loss: 1.7260\n",
      "Epoch [4/6], Step [6300/12188], Loss: 1.7299\n",
      "Epoch [4/6], Step [6400/12188], Loss: 1.7272\n",
      "Epoch [4/6], Step [6500/12188], Loss: 1.7302\n",
      "Epoch [4/6], Step [6600/12188], Loss: 1.7219\n",
      "Epoch [4/6], Step [6700/12188], Loss: 1.7126\n",
      "Epoch [4/6], Step [6800/12188], Loss: 1.7236\n",
      "Epoch [4/6], Step [6900/12188], Loss: 1.7160\n",
      "Epoch [4/6], Step [7000/12188], Loss: 1.7346\n",
      "Epoch [4/6], Step [7100/12188], Loss: 1.7413\n",
      "Epoch [4/6], Step [7200/12188], Loss: 1.7495\n",
      "Epoch [4/6], Step [7300/12188], Loss: 1.7136\n",
      "Epoch [4/6], Step [7400/12188], Loss: 1.7303\n",
      "Epoch [4/6], Step [7500/12188], Loss: 1.7339\n",
      "Epoch [4/6], Step [7600/12188], Loss: 1.7422\n",
      "Epoch [4/6], Step [7700/12188], Loss: 1.7226\n",
      "Epoch [4/6], Step [7800/12188], Loss: 1.7604\n",
      "Epoch [4/6], Step [7900/12188], Loss: 1.7434\n",
      "Epoch [4/6], Step [8000/12188], Loss: 1.7359\n",
      "Epoch [4/6], Step [8100/12188], Loss: 1.7199\n",
      "Epoch [4/6], Step [8200/12188], Loss: 1.7434\n",
      "Epoch [4/6], Step [8300/12188], Loss: 1.7364\n",
      "Epoch [4/6], Step [8400/12188], Loss: 1.7268\n",
      "Epoch [4/6], Step [8500/12188], Loss: 1.7590\n",
      "Epoch [4/6], Step [8600/12188], Loss: 1.7403\n",
      "Epoch [4/6], Step [8700/12188], Loss: 1.7537\n",
      "Epoch [4/6], Step [8800/12188], Loss: 1.7582\n",
      "Epoch [4/6], Step [8900/12188], Loss: 1.7491\n",
      "Epoch [4/6], Step [9000/12188], Loss: 1.7455\n",
      "Epoch [4/6], Step [9100/12188], Loss: 1.7461\n",
      "Epoch [4/6], Step [9200/12188], Loss: 1.7504\n",
      "Epoch [4/6], Step [9300/12188], Loss: 1.7315\n",
      "Epoch [4/6], Step [9400/12188], Loss: 1.7587\n",
      "Epoch [4/6], Step [9500/12188], Loss: 1.7410\n",
      "Epoch [4/6], Step [9600/12188], Loss: 1.7291\n",
      "Epoch [4/6], Step [9700/12188], Loss: 1.7487\n",
      "Epoch [4/6], Step [9800/12188], Loss: 1.7663\n",
      "Epoch [4/6], Step [9900/12188], Loss: 1.7545\n",
      "Epoch [4/6], Step [10000/12188], Loss: 1.7434\n",
      "Epoch [4/6], Step [10100/12188], Loss: 1.7371\n",
      "Epoch [4/6], Step [10200/12188], Loss: 1.7385\n",
      "Epoch [4/6], Step [10300/12188], Loss: 1.7539\n",
      "Epoch [4/6], Step [10400/12188], Loss: 1.7519\n",
      "Epoch [4/6], Step [10500/12188], Loss: 1.7486\n",
      "Epoch [4/6], Step [10600/12188], Loss: 1.7528\n",
      "Epoch [4/6], Step [10700/12188], Loss: 1.7531\n",
      "Epoch [4/6], Step [10800/12188], Loss: 1.7660\n",
      "Epoch [4/6], Step [10900/12188], Loss: 1.7706\n",
      "Epoch [4/6], Step [11000/12188], Loss: 1.7633\n",
      "Epoch [4/6], Step [11100/12188], Loss: 1.7552\n",
      "Epoch [4/6], Step [11200/12188], Loss: 1.7667\n",
      "Epoch [4/6], Step [11300/12188], Loss: 1.7806\n",
      "Epoch [4/6], Step [11400/12188], Loss: 1.7856\n",
      "Epoch [4/6], Step [11500/12188], Loss: 1.7811\n",
      "Epoch [4/6], Step [11600/12188], Loss: 1.7775\n",
      "Epoch [4/6], Step [11700/12188], Loss: 1.7541\n",
      "Epoch [4/6], Step [11800/12188], Loss: 1.7576\n",
      "Epoch [4/6], Step [11900/12188], Loss: 1.7791\n",
      "Epoch [4/6], Step [12000/12188], Loss: 1.7643\n",
      "Epoch [4/6], Step [12100/12188], Loss: 1.7798\n",
      "Epoch [5/6], Step [100/12188], Loss: 1.4137\n",
      "Epoch [5/6], Step [200/12188], Loss: 1.4232\n",
      "Epoch [5/6], Step [300/12188], Loss: 1.4142\n",
      "Epoch [5/6], Step [400/12188], Loss: 1.3989\n",
      "Epoch [5/6], Step [500/12188], Loss: 1.4122\n",
      "Epoch [5/6], Step [600/12188], Loss: 1.4474\n",
      "Epoch [5/6], Step [700/12188], Loss: 1.4356\n",
      "Epoch [5/6], Step [800/12188], Loss: 1.4307\n",
      "Epoch [5/6], Step [900/12188], Loss: 1.4410\n",
      "Epoch [5/6], Step [1000/12188], Loss: 1.4570\n",
      "Epoch [5/6], Step [1100/12188], Loss: 1.4692\n",
      "Epoch [5/6], Step [1200/12188], Loss: 1.4402\n",
      "Epoch [5/6], Step [1300/12188], Loss: 1.4621\n",
      "Epoch [5/6], Step [1400/12188], Loss: 1.4815\n",
      "Epoch [5/6], Step [1500/12188], Loss: 1.4682\n",
      "Epoch [5/6], Step [1600/12188], Loss: 1.4475\n",
      "Epoch [5/6], Step [1700/12188], Loss: 1.4824\n",
      "Epoch [5/6], Step [1800/12188], Loss: 1.4584\n",
      "Epoch [5/6], Step [1900/12188], Loss: 1.4490\n",
      "Epoch [5/6], Step [2000/12188], Loss: 1.4585\n",
      "Epoch [5/6], Step [2100/12188], Loss: 1.4990\n",
      "Epoch [5/6], Step [2200/12188], Loss: 1.4619\n",
      "Epoch [5/6], Step [2300/12188], Loss: 1.4955\n",
      "Epoch [5/6], Step [2400/12188], Loss: 1.4885\n",
      "Epoch [5/6], Step [2500/12188], Loss: 1.4841\n",
      "Epoch [5/6], Step [2600/12188], Loss: 1.4977\n",
      "Epoch [5/6], Step [2700/12188], Loss: 1.4981\n",
      "Epoch [5/6], Step [2800/12188], Loss: 1.4885\n",
      "Epoch [5/6], Step [2900/12188], Loss: 1.4686\n",
      "Epoch [5/6], Step [3000/12188], Loss: 1.4930\n",
      "Epoch [5/6], Step [3100/12188], Loss: 1.4967\n",
      "Epoch [5/6], Step [3200/12188], Loss: 1.5083\n",
      "Epoch [5/6], Step [3300/12188], Loss: 1.4725\n",
      "Epoch [5/6], Step [3400/12188], Loss: 1.5137\n",
      "Epoch [5/6], Step [3500/12188], Loss: 1.4934\n",
      "Epoch [5/6], Step [3600/12188], Loss: 1.5012\n",
      "Epoch [5/6], Step [3700/12188], Loss: 1.5157\n",
      "Epoch [5/6], Step [3800/12188], Loss: 1.4923\n",
      "Epoch [5/6], Step [3900/12188], Loss: 1.4788\n",
      "Epoch [5/6], Step [4000/12188], Loss: 1.5181\n",
      "Epoch [5/6], Step [4100/12188], Loss: 1.5006\n",
      "Epoch [5/6], Step [4200/12188], Loss: 1.5208\n",
      "Epoch [5/6], Step [4300/12188], Loss: 1.5147\n",
      "Epoch [5/6], Step [4400/12188], Loss: 1.5241\n",
      "Epoch [5/6], Step [4500/12188], Loss: 1.5321\n",
      "Epoch [5/6], Step [4600/12188], Loss: 1.5078\n",
      "Epoch [5/6], Step [4700/12188], Loss: 1.5214\n",
      "Epoch [5/6], Step [4800/12188], Loss: 1.5060\n",
      "Epoch [5/6], Step [4900/12188], Loss: 1.5448\n",
      "Epoch [5/6], Step [5000/12188], Loss: 1.5326\n",
      "Epoch [5/6], Step [5100/12188], Loss: 1.5257\n",
      "Epoch [5/6], Step [5200/12188], Loss: 1.5484\n",
      "Epoch [5/6], Step [5300/12188], Loss: 1.5467\n",
      "Epoch [5/6], Step [5400/12188], Loss: 1.5225\n",
      "Epoch [5/6], Step [5500/12188], Loss: 1.5242\n",
      "Epoch [5/6], Step [5600/12188], Loss: 1.5263\n",
      "Epoch [5/6], Step [5700/12188], Loss: 1.5560\n",
      "Epoch [5/6], Step [5800/12188], Loss: 1.5607\n",
      "Epoch [5/6], Step [5900/12188], Loss: 1.5528\n",
      "Epoch [5/6], Step [6000/12188], Loss: 1.5483\n",
      "Epoch [5/6], Step [6100/12188], Loss: 1.5432\n",
      "Epoch [5/6], Step [6200/12188], Loss: 1.5639\n",
      "Epoch [5/6], Step [6300/12188], Loss: 1.5587\n",
      "Epoch [5/6], Step [6400/12188], Loss: 1.5445\n",
      "Epoch [5/6], Step [6500/12188], Loss: 1.5369\n",
      "Epoch [5/6], Step [6600/12188], Loss: 1.5750\n",
      "Epoch [5/6], Step [6700/12188], Loss: 1.5505\n",
      "Epoch [5/6], Step [6800/12188], Loss: 1.5570\n",
      "Epoch [5/6], Step [6900/12188], Loss: 1.5463\n",
      "Epoch [5/6], Step [7000/12188], Loss: 1.5538\n",
      "Epoch [5/6], Step [7100/12188], Loss: 1.5248\n",
      "Epoch [5/6], Step [7200/12188], Loss: 1.5572\n",
      "Epoch [5/6], Step [7300/12188], Loss: 1.5560\n",
      "Epoch [5/6], Step [7400/12188], Loss: 1.5406\n",
      "Epoch [5/6], Step [7500/12188], Loss: 1.5755\n",
      "Epoch [5/6], Step [7600/12188], Loss: 1.5685\n",
      "Epoch [5/6], Step [7700/12188], Loss: 1.5969\n",
      "Epoch [5/6], Step [7800/12188], Loss: 1.5585\n",
      "Epoch [5/6], Step [7900/12188], Loss: 1.5482\n",
      "Epoch [5/6], Step [8000/12188], Loss: 1.5531\n",
      "Epoch [5/6], Step [8100/12188], Loss: 1.5816\n",
      "Epoch [5/6], Step [8200/12188], Loss: 1.5651\n",
      "Epoch [5/6], Step [8300/12188], Loss: 1.5728\n",
      "Epoch [5/6], Step [8400/12188], Loss: 1.5920\n",
      "Epoch [5/6], Step [8500/12188], Loss: 1.5829\n",
      "Epoch [5/6], Step [8600/12188], Loss: 1.5512\n",
      "Epoch [5/6], Step [8700/12188], Loss: 1.5696\n",
      "Epoch [5/6], Step [8800/12188], Loss: 1.5954\n",
      "Epoch [5/6], Step [8900/12188], Loss: 1.5727\n",
      "Epoch [5/6], Step [9000/12188], Loss: 1.5885\n",
      "Epoch [5/6], Step [9100/12188], Loss: 1.5815\n",
      "Epoch [5/6], Step [9200/12188], Loss: 1.5758\n",
      "Epoch [5/6], Step [9300/12188], Loss: 1.6036\n",
      "Epoch [5/6], Step [9400/12188], Loss: 1.6014\n",
      "Epoch [5/6], Step [9500/12188], Loss: 1.5821\n",
      "Epoch [5/6], Step [9600/12188], Loss: 1.5890\n",
      "Epoch [5/6], Step [9700/12188], Loss: 1.5795\n",
      "Epoch [5/6], Step [9800/12188], Loss: 1.5952\n",
      "Epoch [5/6], Step [9900/12188], Loss: 1.6082\n",
      "Epoch [5/6], Step [10000/12188], Loss: 1.6113\n",
      "Epoch [5/6], Step [10100/12188], Loss: 1.5794\n",
      "Epoch [5/6], Step [10200/12188], Loss: 1.5908\n",
      "Epoch [5/6], Step [10300/12188], Loss: 1.5999\n",
      "Epoch [5/6], Step [10400/12188], Loss: 1.6014\n",
      "Epoch [5/6], Step [10500/12188], Loss: 1.5908\n",
      "Epoch [5/6], Step [10600/12188], Loss: 1.6088\n",
      "Epoch [5/6], Step [10700/12188], Loss: 1.6012\n",
      "Epoch [5/6], Step [10800/12188], Loss: 1.6137\n",
      "Epoch [5/6], Step [10900/12188], Loss: 1.6238\n",
      "Epoch [5/6], Step [11000/12188], Loss: 1.6464\n",
      "Epoch [5/6], Step [11100/12188], Loss: 1.6212\n",
      "Epoch [5/6], Step [11200/12188], Loss: 1.6171\n",
      "Epoch [5/6], Step [11300/12188], Loss: 1.5920\n",
      "Epoch [5/6], Step [11400/12188], Loss: 1.5935\n",
      "Epoch [5/6], Step [11500/12188], Loss: 1.6273\n",
      "Epoch [5/6], Step [11600/12188], Loss: 1.6033\n",
      "Epoch [5/6], Step [11700/12188], Loss: 1.6376\n",
      "Epoch [5/6], Step [11800/12188], Loss: 1.6305\n",
      "Epoch [5/6], Step [11900/12188], Loss: 1.6107\n",
      "Epoch [5/6], Step [12000/12188], Loss: 1.6079\n",
      "Epoch [5/6], Step [12100/12188], Loss: 1.6098\n",
      "Epoch [6/6], Step [100/12188], Loss: 1.2693\n",
      "Epoch [6/6], Step [200/12188], Loss: 1.2786\n",
      "Epoch [6/6], Step [300/12188], Loss: 1.2466\n",
      "Epoch [6/6], Step [400/12188], Loss: 1.2665\n",
      "Epoch [6/6], Step [500/12188], Loss: 1.2855\n",
      "Epoch [6/6], Step [600/12188], Loss: 1.2900\n",
      "Epoch [6/6], Step [700/12188], Loss: 1.2744\n",
      "Epoch [6/6], Step [800/12188], Loss: 1.2969\n",
      "Epoch [6/6], Step [900/12188], Loss: 1.3030\n",
      "Epoch [6/6], Step [1000/12188], Loss: 1.2657\n",
      "Epoch [6/6], Step [1100/12188], Loss: 1.2695\n",
      "Epoch [6/6], Step [1200/12188], Loss: 1.3063\n",
      "Epoch [6/6], Step [1300/12188], Loss: 1.3022\n",
      "Epoch [6/6], Step [1400/12188], Loss: 1.2950\n",
      "Epoch [6/6], Step [1500/12188], Loss: 1.2943\n",
      "Epoch [6/6], Step [1600/12188], Loss: 1.3427\n",
      "Epoch [6/6], Step [1700/12188], Loss: 1.3149\n",
      "Epoch [6/6], Step [1800/12188], Loss: 1.3035\n",
      "Epoch [6/6], Step [1900/12188], Loss: 1.3080\n",
      "Epoch [6/6], Step [2000/12188], Loss: 1.3134\n",
      "Epoch [6/6], Step [2100/12188], Loss: 1.3078\n",
      "Epoch [6/6], Step [2200/12188], Loss: 1.3214\n",
      "Epoch [6/6], Step [2300/12188], Loss: 1.3199\n",
      "Epoch [6/6], Step [2400/12188], Loss: 1.3095\n",
      "Epoch [6/6], Step [2500/12188], Loss: 1.3122\n",
      "Epoch [6/6], Step [2600/12188], Loss: 1.3273\n",
      "Epoch [6/6], Step [2700/12188], Loss: 1.3386\n",
      "Epoch [6/6], Step [2800/12188], Loss: 1.3519\n",
      "Epoch [6/6], Step [2900/12188], Loss: 1.3404\n",
      "Epoch [6/6], Step [3000/12188], Loss: 1.3609\n",
      "Epoch [6/6], Step [3100/12188], Loss: 1.3443\n",
      "Epoch [6/6], Step [3200/12188], Loss: 1.3601\n",
      "Epoch [6/6], Step [3300/12188], Loss: 1.3401\n",
      "Epoch [6/6], Step [3400/12188], Loss: 1.3557\n",
      "Epoch [6/6], Step [3500/12188], Loss: 1.3501\n",
      "Epoch [6/6], Step [3600/12188], Loss: 1.3611\n",
      "Epoch [6/6], Step [3700/12188], Loss: 1.3575\n",
      "Epoch [6/6], Step [3800/12188], Loss: 1.3321\n",
      "Epoch [6/6], Step [3900/12188], Loss: 1.3583\n",
      "Epoch [6/6], Step [4000/12188], Loss: 1.3779\n",
      "Epoch [6/6], Step [4100/12188], Loss: 1.3716\n",
      "Epoch [6/6], Step [4200/12188], Loss: 1.3818\n",
      "Epoch [6/6], Step [4300/12188], Loss: 1.3422\n",
      "Epoch [6/6], Step [4400/12188], Loss: 1.3561\n",
      "Epoch [6/6], Step [4500/12188], Loss: 1.3726\n",
      "Epoch [6/6], Step [4600/12188], Loss: 1.3655\n",
      "Epoch [6/6], Step [4700/12188], Loss: 1.3940\n",
      "Epoch [6/6], Step [4800/12188], Loss: 1.3724\n",
      "Epoch [6/6], Step [4900/12188], Loss: 1.3615\n",
      "Epoch [6/6], Step [5000/12188], Loss: 1.3942\n",
      "Epoch [6/6], Step [5100/12188], Loss: 1.3808\n",
      "Epoch [6/6], Step [5200/12188], Loss: 1.3882\n",
      "Epoch [6/6], Step [5300/12188], Loss: 1.3675\n",
      "Epoch [6/6], Step [5400/12188], Loss: 1.3661\n",
      "Epoch [6/6], Step [5500/12188], Loss: 1.3850\n",
      "Epoch [6/6], Step [5600/12188], Loss: 1.4024\n",
      "Epoch [6/6], Step [5700/12188], Loss: 1.3836\n",
      "Epoch [6/6], Step [5800/12188], Loss: 1.4005\n",
      "Epoch [6/6], Step [5900/12188], Loss: 1.3839\n",
      "Epoch [6/6], Step [6000/12188], Loss: 1.3951\n",
      "Epoch [6/6], Step [6100/12188], Loss: 1.4057\n",
      "Epoch [6/6], Step [6200/12188], Loss: 1.3850\n",
      "Epoch [6/6], Step [6300/12188], Loss: 1.4096\n",
      "Epoch [6/6], Step [6400/12188], Loss: 1.3931\n",
      "Epoch [6/6], Step [6500/12188], Loss: 1.4068\n",
      "Epoch [6/6], Step [6600/12188], Loss: 1.4074\n",
      "Epoch [6/6], Step [6700/12188], Loss: 1.3967\n",
      "Epoch [6/6], Step [6800/12188], Loss: 1.4000\n",
      "Epoch [6/6], Step [6900/12188], Loss: 1.4255\n",
      "Epoch [6/6], Step [7000/12188], Loss: 1.4213\n",
      "Epoch [6/6], Step [7100/12188], Loss: 1.4220\n",
      "Epoch [6/6], Step [7200/12188], Loss: 1.4335\n",
      "Epoch [6/6], Step [7300/12188], Loss: 1.4063\n",
      "Epoch [6/6], Step [7400/12188], Loss: 1.4236\n",
      "Epoch [6/6], Step [7500/12188], Loss: 1.4164\n",
      "Epoch [6/6], Step [7600/12188], Loss: 1.4139\n",
      "Epoch [6/6], Step [7700/12188], Loss: 1.4335\n",
      "Epoch [6/6], Step [7800/12188], Loss: 1.4335\n",
      "Epoch [6/6], Step [7900/12188], Loss: 1.4218\n",
      "Epoch [6/6], Step [8000/12188], Loss: 1.4312\n",
      "Epoch [6/6], Step [8100/12188], Loss: 1.4277\n",
      "Epoch [6/6], Step [8200/12188], Loss: 1.4349\n",
      "Epoch [6/6], Step [8300/12188], Loss: 1.4456\n",
      "Epoch [6/6], Step [8400/12188], Loss: 1.4418\n",
      "Epoch [6/6], Step [8500/12188], Loss: 1.4455\n",
      "Epoch [6/6], Step [8600/12188], Loss: 1.4707\n",
      "Epoch [6/6], Step [8700/12188], Loss: 1.4260\n",
      "Epoch [6/6], Step [8800/12188], Loss: 1.4373\n",
      "Epoch [6/6], Step [8900/12188], Loss: 1.4550\n",
      "Epoch [6/6], Step [9000/12188], Loss: 1.4524\n",
      "Epoch [6/6], Step [9100/12188], Loss: 1.4399\n",
      "Epoch [6/6], Step [9200/12188], Loss: 1.4355\n",
      "Epoch [6/6], Step [9300/12188], Loss: 1.4635\n",
      "Epoch [6/6], Step [9400/12188], Loss: 1.4283\n",
      "Epoch [6/6], Step [9500/12188], Loss: 1.4386\n",
      "Epoch [6/6], Step [9600/12188], Loss: 1.4392\n",
      "Epoch [6/6], Step [9700/12188], Loss: 1.4442\n",
      "Epoch [6/6], Step [9800/12188], Loss: 1.4584\n",
      "Epoch [6/6], Step [9900/12188], Loss: 1.4566\n",
      "Epoch [6/6], Step [10000/12188], Loss: 1.4736\n",
      "Epoch [6/6], Step [10100/12188], Loss: 1.4725\n",
      "Epoch [6/6], Step [10200/12188], Loss: 1.4667\n",
      "Epoch [6/6], Step [10300/12188], Loss: 1.4610\n",
      "Epoch [6/6], Step [10400/12188], Loss: 1.4329\n",
      "Epoch [6/6], Step [10500/12188], Loss: 1.4471\n",
      "Epoch [6/6], Step [10600/12188], Loss: 1.4784\n",
      "Epoch [6/6], Step [10700/12188], Loss: 1.4605\n",
      "Epoch [6/6], Step [10800/12188], Loss: 1.4574\n",
      "Epoch [6/6], Step [10900/12188], Loss: 1.4786\n",
      "Epoch [6/6], Step [11000/12188], Loss: 1.4776\n",
      "Epoch [6/6], Step [11100/12188], Loss: 1.4618\n",
      "Epoch [6/6], Step [11200/12188], Loss: 1.4750\n",
      "Epoch [6/6], Step [11300/12188], Loss: 1.4615\n",
      "Epoch [6/6], Step [11400/12188], Loss: 1.4776\n",
      "Epoch [6/6], Step [11500/12188], Loss: 1.4681\n",
      "Epoch [6/6], Step [11600/12188], Loss: 1.4705\n",
      "Epoch [6/6], Step [11700/12188], Loss: 1.4634\n",
      "Epoch [6/6], Step [11800/12188], Loss: 1.4878\n",
      "Epoch [6/6], Step [11900/12188], Loss: 1.4743\n",
      "Epoch [6/6], Step [12000/12188], Loss: 1.4474\n",
      "Epoch [6/6], Step [12100/12188], Loss: 1.4802\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from model import ChessPolicyNet\n",
    "\n",
    "model = ChessPolicyNet().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "epochs = 12\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (batch_x, batch_y) in enumerate(loader):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{len(loader)}], Loss: {running_loss/100:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    torch.save(model.state_dict(), f\"chess_policy_epoch{epoch+1}_v3.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb85611",
   "metadata": {},
   "source": [
    "```python\n",
    "Network: chess_policy_epoch5.pt\n",
    "\n",
    "Epoch [5/5], Step [6000/6094], Loss: 1.5345\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
